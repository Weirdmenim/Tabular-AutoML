# ğŸš€ Tabular AutoML from Scratch

An advanced, modular AutoML pipeline for tabular data â€” built using Python, scikit-learn, and XGBoost.
This project automatically preprocesses data, compares multiple models using cross-validation, and evaluates the best-performing model on a test set with clear metrics and visualizations.

---

## ğŸ“ˆ Project Highlights

* ğŸ“¦ Fully automated pipeline: from data loading to evaluation
* ğŸ› ï¸ Modular codebase with `src/` components
* ğŸ” Model comparison via cross-validation
* âœ… Final evaluation with F1, Precision, Recall, Confusion Matrix & ROC Curve
* ğŸ§ Best model: **XGBoost**, selected automatically

---

## ğŸ“‚ Folder Structure

```
Tabular-AutoML-from-Scratch/
â”œâ”€â”€ data/                     # Raw or preprocessed data (optional)
â”œâ”€â”€ results/
â”‚   â””â”€â”€ best_model.joblib     # Saved best model
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py         # Preprocessing pipeline
â”‚   â”œâ”€â”€ model_selector.py     # Model training & selection
â”‚   â””â”€â”€ evaluate.py           # Evaluation functions
â”œâ”€â”€ main.py                   # Main script
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # You're here
```

---

## ğŸ§ª Dataset

* **Name**: [UCI Adult Income Dataset](https://archive.ics.uci.edu/ml/datasets/adult)
* **Rows**: \~32,000
* **Columns**: 14
* **Task**: Binary classification â€” predict if income > 50K/year

---

## âš™ï¸ Setup & Usage

1. Clone the repo:

   ```bash
   git clone https://github.com/Weirdmenim/Tabular-AutoML/Tabular-AutoML-from-Scratch.git
   cd Tabular-AutoML-from-Scratch
   ```

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

3. Run the pipeline:

   ```bash
   python main.py
   ```

---

## âœ… Evaluation Results

ğŸ“Š **Test Metrics**:

* **F1 Score**: `0.7055`
* **Precision**: `0.7573`
* **Recall**: `0.6605`

ğŸ¯ **Best Model**: `XGBoost`

![ROC Curve](results/roc_curve.png)
![Confusion Matrix](results/confusion_matrix.png)

---

## ğŸ” Key Learnings

* How to modularize an end-to-end ML pipeline
* Automating preprocessing for mixed-type tabular data
* Systematic model evaluation using cross-validation
* Visualizing model performance meaningfully

---

## ğŸ”§ Potential Improvements

* ğŸ” **Hyperparameter Tuning** â€” use `GridSearchCV` or `optuna` to fine-tune XGBoost
* ğŸ“Š **Feature Engineering** â€” add interaction terms or binning for numeric features
* âš™ï¸ **Feature Selection** â€” remove low-importance features (e.g., via SHAP, permutation importance)
* ğŸ§ª **Ensembling** â€” average predictions across multiple models for better generalization
* ğŸ§  **Expand Model Pool** â€” add LightGBM, CatBoost, and stacking classifiers
* ğŸ“Š **Model Monitoring** â€” track metrics over time or across slices (e.g., gender, age)

---

## ğŸ› ï¸ Future Features

* Add YAML-based config support
* CLI interface to control pipeline steps
* Add unit tests for all core components
* Build a simple Streamlit app for upload + prediction

---

## ğŸ“„ License

MIT License â€” free to use, adapt, and share.

---

## ğŸ™Œ Acknowledgments

* [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/adult)
* scikit-learn, XGBoost, pandas, matplotlib
